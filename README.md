# Multimodal RAG for Document Processing ğŸ”  

## ğŸ“Œ Project Overview  
This project implements a **Multimodal Retrieval-Augmented Generation (RAG)** pipeline to extract and process **text, images, and tables** from PDFs.  
It leverages **OCR (Tesseract)** and **Unstructured** to intelligently categorize document elements for AI-driven analysis.  

---

## âœ¨ Key Features  
- ğŸ“œ **Text Extraction** â€“ Retrieves and structures document text.  
- ğŸ–¼ **Image & Table Extraction** â€“ Extracts visuals and tabular data for analysis.  
- ğŸ” **High-Accuracy OCR** â€“ Uses **Tesseract-OCR** for scanned document processing.  
- ğŸ“‚ **Structured Categorization** â€“ Segments data into **headers, footers, titles, tables, images, and text**.  

---

## ğŸ›  Tech Stack  
- **Python** â€“ Backend processing  
- **Unstructured** â€“ Document parsing  
- **Tesseract-OCR** â€“ Optical Character Recognition  
- **Poppler** â€“ PDF processing utilities  
- **Matplotlib** â€“ Data visualization  

---

## ğŸš€ Installation & Setup  

### ğŸ”¹ Clone the repository  
```bash
git clone <repository-link>
cd <project-folder>
